"""
ASI Core - Processor Module
Strukturierung, Anonymisierung und Aufbereitung von Reflexionen
Erweitert mit HRM (Hierarchical Reasoning Model) Integration
"""

import hashlib
import json
import re
from dataclasses import dataclass
from datetime import datetime
from typing import Dict, List, Optional, Tuple

# HRM Integration
try:
    from src.ai.hrm.high_level.planner import Planner
    from src.ai.hrm.low_level.executor import Executor

    HRM_AVAILABLE = True
except ImportError:
    print("HRM Module nicht verf√ºgbar - l√§uft ohne erweiterte KI-Funktionen")
    HRM_AVAILABLE = False


@dataclass
class ProcessedEntry:
    """Strukturierte und verarbeitete Reflexion"""

    original_hash: str
    anonymized_content: str
    structured_data: Dict
    privacy_level: str
    processing_timestamp: datetime
    tags: List[str]
    sentiment: Optional[str] = None
    key_themes: List[str] = None


class ReflectionProcessor:
    """Hauptklasse f√ºr die Verarbeitung von Reflexionen mit HRM-Integration"""

    def __init__(self, embedding_system=None, local_db=None):
        self.anonymization_patterns = {
            "names": r"\b[A-Z][a-z]+\s+[A-Z][a-z]+\b",
            "emails": r"\S+@\S+\.\S+",
            "phones": r"\b\d{3}[-.]?\d{3}[-.]?\d{4}\b",
            "dates": r"\b\d{1,2}[./-]\d{1,2}[./-]\d{2,4}\b",
            "locations": r"\b(in|bei|nach|von)\s+[A-Z][a-z]+\b",
        }

        self.emotion_keywords = {
            "positive": ["gl√ºcklich", "froh", "dankbar", "stolz", "begeistert"],
            "negative": ["traurig", "√§ngstlich", "w√ºtend", "frustriert", "entt√§uscht"],
            "neutral": ["ruhig", "entspannt", "nachdenklich", "m√ºde"],
        }

        # HRM-Integration: Initialisiere KI-Module
        if HRM_AVAILABLE:
            self.hrm_planner = Planner(embedding_system, local_db)
            self.hrm_executor = Executor()
            print("‚úÖ HRM (Hierarchical Reasoning Model) aktiviert")
        else:
            self.hrm_planner = None
            self.hrm_executor = None
            print("‚ö†Ô∏è  HRM nicht verf√ºgbar - Standard-Verarbeitung aktiv")

    def anonymize_content(self, content: str) -> str:
        """
        Anonymisiert pers√∂nliche Informationen in der Reflexion

        Args:
            content: Urspr√ºnglicher Reflexionstext

        Returns:
            str: Anonymisierter Text
        """
        anonymized = content

        # Namen durch Platzhalter ersetzen
        anonymized = re.sub(
            self.anonymization_patterns["names"], "[PERSON]", anonymized
        )

        # E-Mails anonymisieren
        anonymized = re.sub(
            self.anonymization_patterns["emails"], "[EMAIL]", anonymized
        )

        # Telefonnummern entfernen
        anonymized = re.sub(
            self.anonymization_patterns["phones"], "[TELEFON]", anonymized
        )

        # Spezifische Daten anonymisieren
        anonymized = re.sub(self.anonymization_patterns["dates"], "[DATUM]", anonymized)

        # Ortsnamen entfernen
        anonymized = re.sub(
            self.anonymization_patterns["locations"], r"\1 [ORT]", anonymized
        )

        return anonymized

    def extract_emotions(self, content: str) -> Tuple[str, float]:
        """
        Extrahiert Emotionen aus dem Text

        Args:
            content: Text zur Analyse

        Returns:
            Tuple[str, float]: Emotionskategorie und Konfidenz
        """
        content_lower = content.lower()
        emotion_scores = {}

        for emotion_type, keywords in self.emotion_keywords.items():
            score = sum(1 for keyword in keywords if keyword in content_lower)
            emotion_scores[emotion_type] = score

        if not any(emotion_scores.values()):
            return "neutral", 0.5

        dominant_emotion = max(emotion_scores, key=emotion_scores.get)
        confidence = emotion_scores[dominant_emotion] / len(content.split())

        return dominant_emotion, min(confidence * 10, 1.0)

    def extract_themes(self, content: str) -> List[str]:
        """
        Extrahiert Hauptthemen aus der Reflexion

        Args:
            content: Text zur Analyse

        Returns:
            List[str]: Identifizierte Themen
        """
        # Einfache Themen-Extraktion basierend auf Schl√ºsselw√∂rtern
        theme_patterns = {
            "arbeit": ["arbeit", "job", "beruf", "kollege", "chef", "projekt"],
            "beziehungen": ["freund", "familie", "partner", "beziehung", "liebe"],
            "gesundheit": ["gesundheit", "krank", "m√ºde", "energie", "sport"],
            "pers√∂nlichkeit": ["ich", "selbst", "pers√∂nlich", "charakter"],
            "zukunft": ["zukunft", "plan", "ziel", "hoffnung", "traum"],
            "vergangenheit": ["vergangenheit", "erinnerung", "fr√ºher", "damals"],
        }

        content_lower = content.lower()
        identified_themes = []

        for theme, keywords in theme_patterns.items():
            if any(keyword in content_lower for keyword in keywords):
                identified_themes.append(theme)

        return identified_themes

    def structure_content(self, content: str) -> Dict:
        """
        Strukturiert den Inhalt in semantische Bereiche

        Args:
            content: Zu strukturierender Text

        Returns:
            Dict: Strukturierte Daten
        """
        sentences = content.split(".")

        structure = {
            "total_sentences": len(sentences),
            "word_count": len(content.split()),
            "character_count": len(content),
            "sections": [],
        }

        # Einfache Sektionierung basierend auf Abs√§tzen
        paragraphs = content.split("\n\n")
        for i, paragraph in enumerate(paragraphs):
            if paragraph.strip():
                structure["sections"].append(
                    {
                        "index": i,
                        "content": paragraph.strip(),
                        "word_count": len(paragraph.split()),
                        "type": "reflection",
                    }
                )

        return structure

    def process_reflection(self, reflection_data: Dict) -> ProcessedEntry:
        """
        Verarbeitet eine komplette Reflexion mit HRM-Integration

        Args:
            reflection_data: Rohdaten der Reflexion

        Returns:
            ProcessedEntry: Verarbeitete Reflexion mit HRM-Insights
        """
        original_content = reflection_data["content"]

        # Hash f√ºr Originalinhalt erstellen
        original_hash = hashlib.sha256(original_content.encode("utf-8")).hexdigest()[
            :16
        ]

        # Anonymisierung
        anonymized_content = self.anonymize_content(original_content)

        # Strukturierung
        structured_data = self.structure_content(anonymized_content)

        # Emotionsanalyse
        emotion, confidence = self.extract_emotions(anonymized_content)

        # Themen-Extraktion
        themes = self.extract_themes(anonymized_content)

        # üß† HRM-Integration: Hierarchical Reasoning Model
        hrm_insights = None
        if self.hrm_planner and self.hrm_executor:
            try:
                # Bereite Kontext f√ºr HRM vor
                hrm_context = {
                    "content": anonymized_content,
                    "tags": reflection_data.get("tags", []),
                    "timestamp": datetime.now().isoformat(),
                    "emotion": emotion,
                    "themes": themes,
                    "privacy_level": reflection_data.get("privacy_level", "private"),
                }

                # High-Level: Erstelle abstrakten Plan
                abstract_plan = self.hrm_planner.create_plan(hrm_context)

                # Low-Level: Generiere konkrete Aktion
                concrete_action = self.hrm_executor.execute_analysis(
                    abstract_plan, hrm_context
                )

                # Kombiniere HRM-Ergebnisse
                hrm_insights = {
                    "abstract_plan": abstract_plan,
                    "concrete_action": concrete_action,
                    "processing_timestamp": datetime.now().isoformat(),
                    "confidence": abstract_plan.get("confidence_score", 0.5),
                    "recommendations": self._extract_hrm_recommendations(
                        abstract_plan, concrete_action
                    ),
                }

                print(
                    f"‚úÖ HRM-Analyse abgeschlossen - Konfidenz: "
                    f"{hrm_insights['confidence']:.2f}"
                )

            except Exception as e:
                print(f"‚ö†Ô∏è  HRM-Verarbeitung fehlgeschlagen: {e}")
                hrm_insights = {"error": str(e), "fallback_used": True}

        # Erweitere strukturierte Daten um HRM
        if hrm_insights:
            structured_data["hrm"] = hrm_insights

        # Verarbeitete Reflexion erstellen
        processed = ProcessedEntry(
            original_hash=original_hash,
            anonymized_content=anonymized_content,
            structured_data=structured_data,
            privacy_level=reflection_data.get("privacy_level", "private"),
            processing_timestamp=datetime.now(),
            tags=reflection_data.get("tags", []),
            sentiment=f"{emotion}({confidence:.2f})",
            key_themes=themes,
        )

        return processed

    def _extract_hrm_recommendations(
        self, abstract_plan: Dict, concrete_action: Dict
    ) -> List[str]:
        """
        Extrahiert praktische Empfehlungen aus HRM-Ergebnissen

        Args:
            abstract_plan: Abstrakter Plan vom High-Level Planner
            concrete_action: Konkrete Aktion vom Low-Level Executor

        Returns:
            Liste von praktischen Empfehlungen
        """
        recommendations = []

        # Empfehlungen aus abstraktem Plan
        if abstract_plan.get("strategic_recommendations"):
            for rec in abstract_plan["strategic_recommendations"][:2]:
                recommendations.append(
                    f"üìã {rec.get('title', 'Strategisch')}: "
                    f"{rec.get('description', 'Keine Details')}"
                )

        # Empfehlungen aus konkreter Aktion
        if concrete_action and concrete_action.get("suggestion"):
            recommendations.append(
                f"üéØ N√§chster Schritt: " f"{concrete_action['suggestion']}"
            )

        # Langfristige Einsichten
        if abstract_plan.get("long_term_insights"):
            for insight in abstract_plan["long_term_insights"][:2]:
                recommendations.append(f"üí° Einsicht: {insight}")

        # Fallback wenn keine Empfehlungen
        if not recommendations:
            recommendations.append(
                "üîÑ Setze deine Reflexionspraxis fort f√ºr " "tiefere Einsichten"
            )

        return recommendations[:5]  # Maximal 5 Empfehlungen

    def batch_process(self, reflections: List[Dict]) -> List[ProcessedEntry]:
        """
        Verarbeitet mehrere Reflexionen

        Args:
            reflections: Liste von Reflexions-Daten

        Returns:
            List[ProcessedEntry]: Liste verarbeiteter Reflexionen
        """
        return [self.process_reflection(ref) for ref in reflections]

    def export_processed(self, processed_entry: ProcessedEntry) -> Dict:
        """
        Exportiert verarbeitete Daten

        Args:
            processed_entry: Verarbeitete Reflexion

        Returns:
            Dict: Exportierbare Daten
        """
        return {
            "hash": processed_entry.original_hash,
            "content": processed_entry.anonymized_content,
            "structure": processed_entry.structured_data,
            "privacy": processed_entry.privacy_level,
            "timestamp": processed_entry.processing_timestamp.isoformat(),
            "tags": processed_entry.tags,
            "sentiment": processed_entry.sentiment,
            "themes": processed_entry.key_themes,
        }


def detect_cognitive_biases(content: str) -> List[Dict]:
    """
    Erkennt kognitive Verzerrungen und Denkfallen in Text

    Args:
        content: Der zu analysierende Text

    Returns:
        Liste von erkannten Denkfallen mit Details
    """
    biases = []

    # Absolute Begriffe
    absolute_pattern = r"\b(immer|nie|niemals|alle|niemand|jeder|keiner|stets|st√§ndig|dauernd|komplett|v√∂llig|total|absolut|definitiv|garantiert)\b"
    absolute_matches = list(re.finditer(absolute_pattern, content, re.IGNORECASE))

    if absolute_matches:
        instances = [match.group() for match in absolute_matches]
        positions = [[match.start(), match.end()] for match in absolute_matches]
        biases.append(
            {
                "type": "absolute_terms",
                "instances": instances,
                "positions": positions,
                "suggestion": "K√∂nntest du pr√§zisieren, wie oft das wirklich zutrifft? Vielleicht 'oft', 'meist' oder 'in vielen F√§llen'?",
            }
        )

    # √úbergeneralisierungen
    generalization_patterns = [
        r"\b(jeder denkt|alle denken|alle sagen|niemand versteht|keiner mag|alle hassen|jeder wei√ü)\b",
        r"\b(das passiert st√§ndig|das ist immer so|das funktioniert nie)\b",
        r"\b(typisch f√ºr|so sind alle|wie alle anderen)\b",
    ]

    for pattern in generalization_patterns:
        gen_matches = list(re.finditer(pattern, content, re.IGNORECASE))
        if gen_matches:
            instances = [match.group() for match in gen_matches]
            positions = [[match.start(), match.end()] for match in gen_matches]
            biases.append(
                {
                    "type": "overgeneralization",
                    "instances": instances,
                    "positions": positions,
                    "suggestion": "K√∂nntest du spezifischer werden? Welche konkreten Personen oder Situationen meinst du?",
                }
            )
            break

    # Kreisdenken (Zirkelschl√ºsse)
    circular_patterns = [
        r"\b(weil das so ist|das ist so, weil|es ist richtig, weil es richtig ist)\b",
        r"\b(das funktioniert, weil es funktioniert|das ist gut, weil es gut ist)\b",
        r"\b(ich habe recht, weil|das stimmt, weil das stimmt)\b",
    ]

    for pattern in circular_patterns:
        circular_matches = list(re.finditer(pattern, content, re.IGNORECASE))
        if circular_matches:
            instances = [match.group() for match in circular_matches]
            positions = [[match.start(), match.end()] for match in circular_matches]
            biases.append(
                {
                    "type": "circular_reasoning",
                    "instances": instances,
                    "positions": positions,
                    "suggestion": "K√∂nntest du eine unabh√§ngige Begr√ºndung finden? Was sind die konkreten Gr√ºnde oder Belege?",
                }
            )
            break

    # Emotionale √úbertreibungen
    emotional_pattern = r"\b(katastrophal|schrecklich|furchtbar|grauenhaft|wundervoll|perfekt|fantastisch|unglaublich|unm√∂glich|unertr√§glich)\b"
    emotional_matches = list(re.finditer(emotional_pattern, content, re.IGNORECASE))

    if emotional_matches:
        instances = [match.group() for match in emotional_matches]
        positions = [[match.start(), match.end()] for match in emotional_matches]
        biases.append(
            {
                "type": "emotional_extremes",
                "instances": instances,
                "positions": positions,
                "suggestion": "K√∂nntest du beschreiben, was genau dich so bewegt? Vielleicht mit konkreten Beispielen?",
            }
        )

    return biases


def generate_refinement_suggestions(biases: List[Dict]) -> Dict:
    """
    Generiert sanfte Vorschl√§ge zur Pr√§zisierung basierend auf erkannten Denkfallen

    Args:
        biases: Liste von erkannten Denkfallen

    Returns:
        Strukturierte Verbesserungsvorschl√§ge
    """
    suggestions = {"summary": "", "alternatives": [], "questions": []}

    if not biases:
        suggestions["summary"] = "Dein Text ist klar und ausgewogen formuliert."
        return suggestions

    bias_types = [bias["type"] for bias in biases]

    # Zusammenfassung generieren
    if "absolute_terms" in bias_types:
        suggestions["summary"] = "Ich bemerke einige absolute Begriffe. "
    if "overgeneralization" in bias_types:
        suggestions["summary"] += "M√∂glicherweise k√∂nntest du spezifischer werden. "
    if "circular_reasoning" in bias_types:
        suggestions["summary"] += "Die Begr√ºndung k√∂nnte konkreter sein. "

    # Alternative Formulierungen
    for bias in biases:
        if bias["type"] == "absolute_terms":
            suggestions["alternatives"].extend(
                [
                    "Statt 'immer' ‚Üí 'oft' oder 'meistens'",
                    "Statt 'nie' ‚Üí 'selten' oder 'bisher nicht'",
                    "Statt 'alle' ‚Üí 'viele' oder 'die meisten'",
                ]
            )
        elif bias["type"] == "overgeneralization":
            suggestions["alternatives"].extend(
                [
                    "Statt 'jeder denkt' ‚Üí 'in meinem Umfeld denken manche'",
                    "Statt 'das passiert st√§ndig' ‚Üí 'das ist mir schon mehrmals aufgefallen'",
                ]
            )

    # Reflexionsfragen
    suggestions["questions"] = [
        "Gibt es Ausnahmen zu dieser Aussage?",
        "Welche konkreten Beispiele fallen dir ein?",
        "Wie k√∂nntest du das pr√§ziser ausdr√ºcken?",
    ]

    return suggestions


if __name__ == "__main__":
    # Beispiel-Nutzung
    processor = ReflectionProcessor()

    # Test-Reflexion
    test_reflection = {
        "content": """Heute hatte ich ein schwieriges Gespr√§ch mit Max Mustermann. 
        Wir haben √ºber die Zukunft unserer Beziehung gesprochen. 
        Ich f√ºhle mich traurig aber auch hoffnungsvoll.
        Meine E-Mail max@example.com ist √ºbrigens.""",
        "tags": ["beziehung", "gespr√§ch"],
        "privacy_level": "anonymous",
    }

    # Verarbeitung
    processed = processor.process_reflection(test_reflection)

    # Ausgabe
    exported = processor.export_processed(processed)
    print(json.dumps(exported, indent=2, ensure_ascii=False))
