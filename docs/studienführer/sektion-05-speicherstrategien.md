# Sektion V ‚Äì Speicherstrategien (FR-010)

**Traceability**: Erf√ºllt FR-010 - "Content MUST cover all four storage strategies (IPFS, Arweave, Storacha, Polygon) and their specific use cases"

## Lernziele

Nach Abschluss dieser Sektion sollten Sie in der Lage sein:

- Vier Strategien unterscheiden und zuordnen: **IPFS**, **Arweave**, **Storacha** (lt. Spez), **Polygon (Anchoring)**
- Trade-offs bzgl. Persistenz, Kosten, Latenz, Abrufgarantien und Datenschutz (verschl√ºsselt, PII-frei) bewerten
- Hybrid-Flows lokal‚Üîdezentral erkl√§ren und korrekt anwenden
- Entscheidungslogik f√ºr Speicherstrategie-Auswahl basierend auf Anwendungsfall treffen
- Datenschutz-Implikationen jeder Speicherstrategie verstehen und ber√ºcksichtigen

---

## √úberblick

Das ASI Core System implementiert eine **Multi-Layer Storage-Strategie**, die verschiedene dezentrale Speichernetzwerke f√ºr unterschiedliche Anforderungen kombiniert. Das Design folgt dem Grundprinzip:

- **Lokal zuerst:** Inhalte entstehen/bleiben lokal (verschl√ºsselt)
- **Dezentral danach:** Nur Artefakte/Proofs/Hashes verlassen das Ger√§t; Inhalte nur verschl√ºsselt und nur falls n√∂tig
- **Hybrid-Design:** ‚ÄûWarm" (IPFS), ‚ÄûCold/Archive" (Arweave), ‚ÄûEconomic Anchor" (Polygon), ‚ÄûSpezifische Netzkapazit√§t" (Storacha, lt. Spez)

### Designprinzipien f√ºr Speicherung

**1. Privacy First**: Nur verschl√ºsselte Daten oder Hashes verlassen das lokale Ger√§t
**2. Redundanz**: Kritische Daten werden in mehreren Netzwerken gesichert
**3. Cost Efficiency**: Verschiedene Strategien f√ºr verschiedene Kosten-/Nutzen-Profile
**4. Graceful Degradation**: System funktioniert auch bei Ausfall einzelner Speichernetzwerke

---

## Entscheidungsmatrix

| Kriterium                | IPFS                            | Arweave                         | Storacha*                        | Polygon (Anchoring)              |
|-------------------------|----------------------------------|----------------------------------|----------------------------------|----------------------------------|
| **Persistenz**              | Pin-basiert (kein Garant)       | Dauerhaft/bezahlt (Archive)     | Netz-/Provider-abh√§ngig          | On-chain Commit (Hash/Meta)      |
| **Mutabilit√§t**             | versionierbar via CIDs          | immutabel (neue Tx f√ºr Update)  | je nach Dienst                   | unver√§nderbarer Commit           |
| **Kostenmodell**            | Pinning/Host-Kosten              | Einmalig/Prepay f√ºr Speicherung | Dienst-/Nutzungsabh√§ngig         | Tx-Geb√ºhren nur f√ºr Hash         |
| **Latenz/Retrieval**        | gut mit Replicas                | variabel (Archive-Fokus)        | abh√§ngig von Region/Knoten       | n/a (kein Inhalt)                |
| **Abrufgarantien**          | Community/Pin-Provider           | √∂konomisch (Langzeit)           | SLA/Policy-basiert               | Vollst√§ndigkeits-Nachweis        |
| **Datenschutz**             | **nur verschl√ºsselt**            | **nur verschl√ºsselt**           | **nur verschl√ºsselt**            | nur Meta/Hash, keine PII         |
| **Geeignet f√ºr**            | h√§ufige Abrufe, verteilte Daten | Langzeit-Archiv                 | spez. Workloads/Kapazit√§t        | Proof-of-Existence/Integrity     |
| **Risiken**                 | Unpinned Verlust                 | Kostenplanung n√∂tig             | Anbieterbindung/Verf√ºgbarkeit    | Gas-/Geb√ºhren-Schwankungen       |

\* ‚ÄûStoracha" lt. eurer Spezifikation; Technikdetails separat verifizieren.

---

## Detaillierte Strategien

### 1. IPFS (InterPlanetary File System) üåê

**Zweck**: Content-addressable Speicherung f√ºr h√§ufig abgerufene Daten

**Charakteristika**:
- **Content-Addressing**: Dateien werden √ºber ihre Hashes (CIDs) referenziert
- **Peer-to-Peer**: Dezentrale Replikation ohne zentrale Server
- **Versionierung**: Neue Versionen erhalten neue CIDs, alte bleiben erhalten
- **Caching**: Nat√ºrliche Verteilung durch lokales Caching bei Abruf

**Anwendung im ASI Core**:
- **Verschl√ºsselte Reflexionen**: Pers√∂nliche Inhalte vor lokaler Verschl√ºsselung
- **√ñffentliche Artefakte**: Anonymisierte Patterns und Erkenntnisse
- **Metadaten**: Strukturierte Daten mit h√§ufigem Zugriff
- **Code/Updates**: Verteilung von System-Updates

**Datenschutz-Implementierung**:
```python
# Beispiel: Verschl√ºsselter IPFS-Upload
async def upload_to_ipfs(content: str, user_key: bytes) -> str:
    # 1. Lokale Verschl√ºsselung
    encrypted = encrypt_aes256(content, user_key)
    
    # 2. IPFS-Upload des verschl√ºsselten Inhalts
    cid = await ipfs_client.add(encrypted)
    
    # 3. Nur CID wird zur√ºckgegeben, nie Klartext
    return cid
```

**Vorteile**:
- Schnelle Abrufzeiten durch geografische Verteilung
- Kosteneffizient f√ºr h√§ufig abgerufene Daten
- Nat√ºrliche Redundanz durch Peer-Netzwerk
- Zensurresistent durch Dezentralisierung

**Nachteile**:
- Keine Persistenz-Garantie ohne Pinning
- Abh√§ngigkeit von Pin-Services oder eigenen Knoten
- Potenzielle Privacy-Risiken ohne Verschl√ºsselung

### 2. Arweave (Permanent Archive) üóÑÔ∏è

**Zweck**: Dauerhafter, unver√§nderlicher Speicher f√ºr kritische Langzeit-Archivierung

**Charakteristika**:
- **Permanenz**: Daten werden f√ºr mindestens 200 Jahre gespeichert
- **Unver√§nderlichkeit**: Einmal geschrieben, nie ver√§nderbar
- **√ñkonomische Nachhaltigkeit**: Einmalzahlung finanziert langfristige Speicherung
- **Endg√ºltigkeit**: Mathematische Garantien f√ºr Datenverf√ºgbarkeit

**Anwendung im ASI Core**:
- **Kritische Reflexionen**: Besonders wertvolle pers√∂nliche Erkenntnisse
- **System-Snapshots**: Wichtige Systemzust√§nde und Konfigurationen
- **Governance-Entscheidungen**: Unver√§nderliche Dokumentation von Beschl√ºssen
- **Proof-Commitments**: Kryptographische Beweise f√ºr sp√§tere Verifikation

**Kosten-Berechnung**:
```python
# Arweave-Kosten basieren auf Datenvolumen
def calculate_arweave_cost(data_size_mb: float) -> float:
    # Approximation: ~$0.005 per MB (Stand 2024)
    base_cost = data_size_mb * 0.005
    # Mit 200-Jahr-Garantie
    return base_cost
```

**Vorteile**:
- Echte Permanenz mit √∂konomischen Garantien
- Unver√§nderlichkeit schafft Vertrauen
- Einmalkosten ohne laufende Geb√ºhren
- Auditierbar und transparent

**Nachteile**:
- Hohe Kosten f√ºr gro√üe Datenmengen
- Langsame Abrufzeiten (Archive-optimiert)
- Unver√§nderlichkeit kann Nachteil sein (Updates unm√∂glich)

### 3. Storacha (Community Storage) ü§ù

**Zweck**: Community-gest√ºtzte Speicherung mit spezifischen Netzkapazit√§ten

**Charakteristika**:
- **Community-Driven**: Speicherung durch Netzwerk-Teilnehmer
- **Belohnungssystem**: Token-Incentives f√ºr Speicher-Provider
- **Flexible SLAs**: Verschiedene Verf√ºgbarkeits- und Persistenz-Level
- **Regionale Optimierung**: Geografische N√§he f√ºr bessere Performance
- **Invisible Mining**: Automatische Teilnahme ohne User-Eingriff bei verf√ºgbaren Ressourcen

**Anwendung im ASI Core**:
- **Kollektive Daten**: Aggregierte, anonymisierte Muster und Statistiken
- **Tempor√§re Speicherung**: Zwischenspeicherung f√ºr Verarbeitungs-Pipelines
- **Community-Ressourcen**: Geteilte Tools und Dokumentation
- **Backup-Strategien**: Zus√§tzliche Redundanz f√ºr kritische Daten

**Token-Integration**:
```python
# $MEM-Token Belohnung f√ºr Speicher-Provider
async def reward_storage_provider(provider_did: str, storage_gb: float, uptime: float):
    base_reward = storage_gb * STORAGE_REWARD_RATE
    uptime_bonus = base_reward * (uptime - 0.95) * UPTIME_MULTIPLIER
    total_reward = base_reward + uptime_bonus
    
    await mint_mem_tokens(provider_did, total_reward)
```

**Vorteile**:
- Wirtschaftliche Anreize f√ºr Speicher-Provider
- Flexibilit√§t bei SLA-Anforderungen
- Community-Integration st√§rkt Netzwerk
- Potenzial f√ºr innovative Speicher-Services

**Nachteile**:
- Abh√§ngigkeit von Community-Teilnahme
- Variable Verf√ºgbarkeit je nach Provider
- Potenzielle Vendor-Lock-In-Risiken
- Noch zu verifizierende Technikdetails

### 4. Polygon (Blockchain Anchoring) ‚öì

**Zweck**: On-Chain Commitments f√ºr Integrit√§t und Proof-of-Existence

**Charakteristika**:
- **Blockchain-Sicherheit**: Unver√§nderliche Commits in Public Blockchain
- **Hash-basiert**: Nur Hashes und Metadaten, nie Inhalte
- **Timestamp-Proof**: Nachweisbare Existenz zu bestimmtem Zeitpunkt
- **Cost-Efficient**: G√ºnstige Layer-2-Transaktionen

**Anwendung im ASI Core**:
- **Reflexions-Commitments**: Beweise f√ºr Existenz ohne Inhalts-Preisgabe
- **System-State-Anchors**: Snapshots von Systemzust√§nden
- **Governance-Votes**: Unver√§nderliche Dokumentation von Entscheidungen
- **Token-Transaktionen**: $MEM-Token-Transfers und Smart Contract-Calls

**Smart Contract-Beispiel**:
```solidity
contract ASIStateTracker {
    mapping(bytes32 => uint256) public commitments;
    
    function anchorCommitment(bytes32 _hash) external {
        commitments[_hash] = block.timestamp;
        emit StateAnchored(_hash, msg.sender, block.timestamp);
    }
    
    function verifyCommitment(bytes32 _hash) external view returns (uint256) {
        return commitments[_hash]; // 0 if not exists
    }
}
```

**Vorteile**:
- Maximale Unver√§nderlichkeit durch Blockchain-Sicherheit
- G√ºnstige Transaktionen auf Polygon Layer-2
- √ñffentlich verifizierbare Beweise
- Integration mit DeFi-√ñkosystem

**Nachteile**:
- Nur Metadaten, keine Inhalte speicherbar
- Gas-Geb√ºhren k√∂nnen schwanken
- Blockchain-Abh√§ngigkeit
- Potenzielle Skalierungsgrenzen

---

## Referenz-Architektur (Flow)

```mermaid
flowchart LR
    A[Lokaler Inhalt <br/>verschl√ºsselt] --> B{Teilen/Archiv n√∂tig?}
    B --Nein--> Z[Lokale Nutzung]
    B --Ja--> C[Erzeuge Hash/Commitment]
    
    C --> D[IPFS Upload <br/>verschl√ºsselt]
    C --> E[Arweave Archiv <br/>optional]
    C --> F[Polygon Anchor <br/>Tx: Hash/Meta]
    C --> G[Storacha Upload <br/>community]
    
    D -.Verf√ºgbarkeit.-> H[Pin/Replicate]
    E -.Langzeit.-> I[Archiv-Proof]
    F -.Integrit√§t.-> J[On-Chain Commit]
    G -.Community.-> K[Provider Network]
    
    H --> L[Schneller Abruf]
    I --> M[200+ Jahre Garantie]
    J --> N[Proof-of-Existence]
    K --> O[Flexible SLAs]
```

### Datenfluss-Beispiel: Pers√∂nliche Reflexion

**1. Lokale Erstellung**
```python
user_reflection = "Heute habe ich √ºber..."
local_key = generate_user_key()
encrypted_content = encrypt_aes256(user_reflection, local_key)
content_hash = sha256(encrypted_content)
```

**2. Strategieentscheidung**
```python
if user_wants_backup:
    # IPFS f√ºr schnellen Abruf
    ipfs_cid = await upload_to_ipfs(encrypted_content)
    
if is_valuable_insight:
    # Arweave f√ºr Permanenz
    arweave_tx = await archive_to_arweave(encrypted_content)
    
# Polygon f√ºr Proof-of-Existence (immer)
polygon_tx = await anchor_to_polygon(content_hash, metadata)

if share_with_community:
    # Storacha f√ºr Community-Access
    storacha_id = await upload_to_storacha(encrypted_content)
```

**3. Lokale Referenzen**
```python
local_metadata = {
    "content_hash": content_hash,
    "ipfs_cid": ipfs_cid if exists else None,
    "arweave_tx": arweave_tx if exists else None,
    "polygon_tx": polygon_tx,
    "storacha_id": storacha_id if exists else None,
    "encryption_key_ref": key_reference  # Nie im Klartext
}
```

---

## Entscheidungslogik

### Automatische Strategieauswahl

**Kategorien**:
```python
class ContentCategory(Enum):
    PERSONAL_REFLECTION = "personal"      # Lokal + optional IPFS
    VALUABLE_INSIGHT = "valuable"         # + Arweave
    SHARED_PATTERN = "shared"            # + Storacha
    SYSTEM_STATE = "system"              # + Polygon (immer)
    PUBLIC_RESOURCE = "public"           # IPFS + Polygon

def select_storage_strategy(category: ContentCategory, 
                          size_mb: float, 
                          access_frequency: str) -> List[str]:
    strategies = ["polygon"]  # Immer f√ºr Integrity
    
    if category == ContentCategory.PERSONAL_REFLECTION:
        if access_frequency == "high":
            strategies.append("ipfs")
            
    elif category == ContentCategory.VALUABLE_INSIGHT:
        strategies.extend(["ipfs", "arweave"])
        
    elif category == ContentCategory.SHARED_PATTERN:
        strategies.extend(["ipfs", "storacha"])
        
    # Kostencheck
    if size_mb > 100 and "arweave" in strategies:
        # Gro√üe Dateien: Arweave nur f√ºr kritische Inhalte
        if category != ContentCategory.VALUABLE_INSIGHT:
            strategies.remove("arweave")
            
    return strategies
```

### Kosten-Nutzen-Optimierung

**Kostensch√§tzung**:
```python
def estimate_storage_costs(size_mb: float, strategies: List[str]) -> dict:
    costs = {}
    
    if "ipfs" in strategies:
        # $0.10/GB/Monat f√ºr Pinning
        costs["ipfs"] = size_mb / 1024 * 0.10 * 12  # Jahreskosten
        
    if "arweave" in strategies:
        # $0.005/MB einmalig
        costs["arweave"] = size_mb * 0.005
        
    if "storacha" in strategies:
        # Variable, Community-abh√§ngig
        costs["storacha"] = size_mb * 0.002 * 12  # Gesch√§tzt
        
    if "polygon" in strategies:
        # ~$0.001 pro Transaktion
        costs["polygon"] = 0.001
        
    return costs
```

---

## Datenschutz & Compliance

### Verschl√ºsselungsstandards

**AES-256 f√ºr Inhalte**:
```python
def encrypt_for_storage(content: str, user_key: bytes) -> tuple:
    # Generiere zuf√§llige IV
    iv = os.urandom(16)
    
    # AES-256-CBC Verschl√ºsselung
    cipher = AES.new(user_key, AES.MODE_CBC, iv)
    padded_content = pad(content.encode(), AES.block_size)
    encrypted = cipher.encrypt(padded_content)
    
    return iv + encrypted, sha256(encrypted).hexdigest()
```

**Zero-Knowledge Proofs f√ºr Metadaten**:
```python
def create_metadata_proof(content_hash: str, properties: dict) -> str:
    # Beweise Eigenschaften ohne Inhaltspreisgabe
    proof_data = {
        "content_exists": True,
        "word_count_range": get_word_count_bucket(properties["word_count"]),
        "category": properties["category"],
        "timestamp": properties["timestamp"]
    }
    
    # ZK-Proof generieren (vereinfacht)
    return generate_zk_proof(proof_data)
```

### Compliance-Garantien

**GDPR-Konformit√§t**:
- ‚úÖ **Datenminimierung**: Nur notwendige Metadaten in dezentralen Netzwerken
- ‚úÖ **Zweckbindung**: Jede Speicherstrategie hat definierten Zweck
- ‚úÖ **Speicherbegrenzung**: Lokale L√∂schung jederzeit m√∂glich
- ‚úÖ **Integrit√§t**: Kryptographische Sicherung gegen Manipulation
- ‚úÖ **Vertraulichkeit**: End-to-End-Verschl√ºsselung

**Right to be Forgotten**:
```python
async def exercise_right_to_be_forgotten(user_did: str):
    # 1. Lokale Daten l√∂schen (vollst√§ndige Kontrolle)
    await delete_local_data(user_did)
    
    # 2. Verschl√ºsselungsschl√ºssel vernichten
    await destroy_encryption_keys(user_did)
    
    # 3. Dezentrale Daten bleiben, sind aber unlesbar
    # (da nur verschl√ºsselt gespeichert und Schl√ºssel vernichtet)
    
    # 4. Polygon-Anchors bleiben (nur Hashes, keine PII)
    # ‚Üí Compliance durch Design
```

---

## Monitoring & Analytics

### Performance-Metriken

**Verf√ºgbarkeits-Tracking**:
```python
async def check_storage_health():
    health_status = {}
    
    # IPFS-Verf√ºgbarkeit
    ipfs_reachable = await ping_ipfs_gateways()
    health_status["ipfs"] = {
        "available": ipfs_reachable,
        "response_time": await measure_ipfs_latency()
    }
    
    # Arweave-Status
    arweave_healthy = await check_arweave_network()
    health_status["arweave"] = {
        "available": arweave_healthy,
        "sync_status": await get_arweave_sync_status()
    }
    
    return health_status
```

**Kosten-Monitoring**:
```python
def track_storage_economics():
    monthly_costs = {
        "ipfs_pinning": calculate_ipfs_costs(),
        "arweave_archive": calculate_arweave_usage(),
        "polygon_gas": calculate_polygon_fees(),
        "storacha_fees": calculate_storacha_costs()
    }
    
    # Anonymisierte Metriken f√ºr Community
    return anonymize_cost_data(monthly_costs)
```

---

## Disaster Recovery

### Redundanz-Strategien

**Multi-Layer Backup**:
```python
async def ensure_data_redundancy(content_hash: str):
    storage_locations = await get_storage_locations(content_hash)
    
    required_redundancy = 3  # Mindestens 3 Kopien
    available_copies = len(storage_locations)
    
    if available_copies < required_redundancy:
        # Automatische Replikation
        await replicate_to_additional_networks(content_hash)
        
    return await verify_all_copies(content_hash)
```

**Recovery-Prozeduren**:
```python
async def recover_from_storage_failure(failed_network: str):
    affected_content = await find_content_on_network(failed_network)
    
    for content_hash in affected_content:
        alternative_sources = await find_alternative_storage(content_hash)
        
        if not alternative_sources:
            # Kritischer Datenverlust
            await alert_user_of_data_loss(content_hash)
        else:
            # Automatische Wiederherstellung
            await restore_from_alternative(content_hash, alternative_sources[0])
```

---

## Integration mit Token-√ñkonomie

### Storage-Mining-Belohnungen

**Provider-Incentives**:
```python
async def calculate_storage_provider_rewards(provider_did: str, 
                                          epoch: int) -> float:
    # Gespeicherte Daten
    stored_gb = await get_provider_storage_amount(provider_did, epoch)
    
    # Verf√ºgbarkeits-Score
    uptime_score = await get_provider_uptime(provider_did, epoch)
    
    # Basis-Belohnung
    base_reward = stored_gb * STORAGE_REWARD_PER_GB
    
    # Uptime-Bonus
    uptime_bonus = base_reward * (uptime_score - 0.95) * 2.0
    
    # Quality-Bonus (schnelle Antwortzeiten)
    quality_score = await get_provider_quality_score(provider_did, epoch)
    quality_bonus = base_reward * quality_score * 0.1
    
    return base_reward + uptime_bonus + quality_bonus
```

**Slashing f√ºr schlechte Performance**:
```python
async def apply_storage_slashing(provider_did: str, violation: str):
    slash_amounts = {
        "data_loss": 0.5,      # 50% der gestakten Token
        "extended_downtime": 0.2,  # 20% der gestakten Token
        "slow_response": 0.05     # 5% der gestakten Token
    }
    
    slash_percentage = slash_amounts.get(violation, 0)
    staked_amount = await get_staked_tokens(provider_did)
    slash_amount = staked_amount * slash_percentage
    
    await slash_tokens(provider_did, slash_amount)
    await redistribute_slashed_tokens_to_network(slash_amount)
```

---

## Traceability & Compliance

**Erf√ºllt FR-010 vollst√§ndig**:
- ‚úÖ **IPFS**: Content-addressable Speicherung f√ºr h√§ufige Abrufe
- ‚úÖ **Arweave**: Permanente Archivierung mit 200-Jahr-Garantie
- ‚úÖ **Storacha**: Community-gest√ºtzte Speicherung mit Token-Incentives
- ‚úÖ **Polygon**: Blockchain-Anchoring f√ºr Integrity-Proofs

**Integration mit anderen Sektionen**:
- **Sektion I**: Kernprinzipien "F√ºr immer" durch Multi-Layer-Strategie
- **Sektion II**: Technische Architektur f√ºr Storage-Abstraktion
- **Sektion III**: Token-√ñkonomie f√ºr Storage-Provider-Belohnungen
- **Sektion IV**: Datenschutz durch Verschl√ºsselung in allen Netzwerken

**Weiterf√ºhrende Entwicklung**:
- K√ºnftige Quiz-Erweiterung: Storage-spezifische Fragen zu Trade-offs
- Praktische Implementierung: Storage-Client-APIs
- Governance: Community-Entscheidungen √ºber Storage-Parameter
